{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/programmer/master_2/project/Decoupling-Representation-Learning-from-Reinforcement-Learning'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from stable_baselines3 import DQN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'net_arch': [64, 64]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "policy_kwargs = {\n",
    "         \"net_arch\": [64] * 2,\n",
    "     }\n",
    "\n",
    "\n",
    "policy_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQN(env=env,policy_kwargs=policy_kwargs, policy = 'MlpPolicy', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = agent.q_net.features_extractor\n",
    "latent_size = agent.q_net.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_samples(\n",
    "    seq_of_obs: torch.tensor,\n",
    "    prediction_length_k: int, ):\n",
    "    \"\"\"\n",
    "    each obs is allready a framesack, so we can just go util length - k\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    for i in range(seq_of_obs.shape[0] - prediction_length_k):\n",
    "        anchor = seq_of_obs[i]\n",
    "        positive = seq_of_obs[i + prediction_length_k]\n",
    "        samples.append(torch.stack((anchor, positive), dim=0))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "def create_dataset(env, episodes = 1, seed=0):\n",
    "    samples = []\n",
    "    env.seed(0)\n",
    "    env.action_space.seed(0)\n",
    "    for i_epiosde in range(episodes):\n",
    "        obs = env.reset()\n",
    "        seq_of_obs = torch.tensor(np.array(obs), dtype=torch.float32).unsqueeze(0)\n",
    "        while True:\n",
    "            action = env.action_space.sample()\n",
    "            next_obs, reward, done, _ = env.step(action)\n",
    "            if done:\n",
    "                break\n",
    "            seq_of_obs = torch.cat((seq_of_obs, torch.tensor(np.array(next_obs), dtype=torch.float32).unsqueeze(0),), dim=0)\n",
    "    return extract_samples(seq_of_obs, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder params\n",
      "forward_mlp paramas\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([8, 8])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([8])\n",
      "W params\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device= \"cpu\"\n",
    "dataset = create_dataset(env=env)\n",
    "encoder = copy.deepcopy(feature_extractor).to(device)\n",
    "target_encoder = copy.deepcopy(encoder).to(device)\n",
    "forward_mlp = create_net(\n",
    "            input_size=latent_size, output_size=latent_size\n",
    "        ).to(device)\n",
    "W = torch.nn.Linear(latent_size, latent_size, bias=False).to(device)\n",
    "params = []\n",
    "print(\"encoder params\")\n",
    "for param in encoder.parameters():\n",
    "    print(type(param), param.size())\n",
    "print(\"forward_mlp paramas\")\n",
    "for param in forward_mlp.parameters():\n",
    "    print(type(param), param.size())\n",
    "print(\"W params\")\n",
    "for param in W.parameters():\n",
    "    print(type(param), param.size())\n",
    "\n",
    "    \n",
    "params += encoder.parameters()\n",
    "params += forward_mlp.parameters()\n",
    "params += W.parameters()\n",
    "optim = torch.optim.Adam(params=params)\n",
    "        \n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25426/802128717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epiosde {} loss {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " def extract_samples(\n",
    "        seq_of_obs: torch.tensor,\n",
    "        prediction_length_k: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        each obs is allready a framesack, so we can just go util length - k\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for i in range(seq_of_obs.shape[0] - prediction_length_k):\n",
    "            anchor = seq_of_obs[i]\n",
    "            positive = seq_of_obs[i + prediction_length_k]\n",
    "            samples.append(torch.stack((anchor, positive), dim=0))\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net(input_size, output_size, hidden_sizes: Sequence = None):\n",
    "        sequence = list()\n",
    "        if hidden_sizes is None:\n",
    "            hidden_sizes = []\n",
    "        hidden_layers = [\n",
    "            torch.nn.Linear(n_in, n_out)\n",
    "            for n_in, n_out in zip([input_size] + hidden_sizes[:-1], hidden_sizes)\n",
    "        ]\n",
    "\n",
    "        for layer in hidden_layers:\n",
    "            sequence.extend([layer, torch.nn.ReLU()])\n",
    "        # add last layer without ReLU, also serves as first layer if we have no hidden layers\n",
    "        last_size = input_size if hidden_sizes == [] else hidden_sizes[-1]\n",
    "        sequence.append(torch.nn.Linear(last_size, output_size))\n",
    "        return torch.nn.Sequential(*sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,\n",
       " tensor([[-0.0025,  1.4028, -0.2551, -0.3607,  0.0029,  0.0578,  0.0000,  0.0000],\n",
       "         [-0.0296,  1.3114, -0.2799, -0.4644,  0.0582,  0.1431,  0.0000,  0.0000]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=8, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "latent_size = 8\n",
    "encoder = 1\n",
    "target_encoder = 0\n",
    "forward_mlp = create_net(input_size=8, output_size=8).to(device)\n",
    "W = torch.nn.Linear(latent_size, latent_size, bias=False).to(device)\n",
    "forward_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_of_obs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class PreTrainer:\n",
    "    def __init__(self, feature_extractor, latent_size, env, device=None) -> None:\n",
    "        self.env = env\n",
    "        self.dataset = self.create_dataset(env=self.env)\n",
    "        self.encoder = copy.deepcopy(feature_extractor).to(device)\n",
    "        self.target_encoder = copy.deepcopy(self.encoder).to(device)\n",
    "        self.forward_mlp = self.create_net(\n",
    "            input_size=latent_size, output_size=latent_size\n",
    "        ).to(device)\n",
    "        self.W = torch.nn.Linear(latent_size, latent_size, bias=False).to(device)\n",
    "        params = []\n",
    "\n",
    "        print(\"encoder params\")\n",
    "        for param in self.encoder.parameters():\n",
    "            print(type(param), param.size())\n",
    "        print(\"forward_mlp paramas\")\n",
    "        for param in self.forward_mlp.parameters():\n",
    "            print(type(param), param.size())\n",
    "        print(\"W params\")\n",
    "        for param in self.W.parameters():\n",
    "            print(type(param), param.size())\n",
    "\n",
    "        params += self.encoder.parameters()\n",
    "        params += self.forward_mlp.parameters()\n",
    "        params += self.W.parameters()\n",
    "        self.optim = torch.optim.Adam(params=params)\n",
    "        self.device = device\n",
    "    \n",
    "    def create_net(self, input_size, output_size, hidden_sizes: Sequence = None):\n",
    "        sequence = list()\n",
    "        if hidden_sizes is None:\n",
    "            hidden_sizes = []\n",
    "        hidden_layers = [\n",
    "            torch.nn.Linear(n_in, n_out)\n",
    "            for n_in, n_out in zip([input_size] + hidden_sizes[:-1], hidden_sizes)\n",
    "        ]\n",
    "\n",
    "        for layer in hidden_layers:\n",
    "            sequence.extend([layer, torch.nn.ReLU()])\n",
    "        # add last layer without ReLU, also serves as first layer if we have no hidden layers\n",
    "        last_size = input_size if hidden_sizes == [] else hidden_sizes[-1]\n",
    "        sequence.append(torch.nn.Linear(last_size, output_size))\n",
    "        return torch.nn.Sequential(*sequence)\n",
    "    \n",
    "    def create_dataset(self, n_episodes: int = 1, env=None):\n",
    "        samples = []\n",
    "        for _ in range(n_episodes):\n",
    "            obs = env.reset()\n",
    "            # first to array to preserver fram stacking\n",
    "            seq_of_obs = torch.tensor(np.array(obs), dtype=torch.float32).unsqueeze(0)\n",
    "            while True:\n",
    "                # we can sample from action space via env.action_space.sample(), effectively creating a random policy\n",
    "                action = env.action_space.sample()\n",
    "                next_obs, reward, done, info = env.step(action)\n",
    "                if done:\n",
    "                    break\n",
    "                # we save it as flaot 32 as the deepset feature excractor is also float32\n",
    "                seq_of_obs = torch.cat(\n",
    "                    (\n",
    "                        seq_of_obs,\n",
    "                        torch.tensor(np.array(next_obs), dtype=torch.float32).unsqueeze(\n",
    "                            0\n",
    "                        ),\n",
    "                    ),\n",
    "                    dim=0,\n",
    "                )\n",
    "            # with this way of extracting samples we have a lot of redundancy,\n",
    "            #  but as eposides have random length I see no clean way to store entore episodes and sample during training\n",
    "            samples += self.extract_samples(\n",
    "                seq_of_obs=seq_of_obs, prediction_length_k=10\n",
    "            )  # should be in dependency of Ts\n",
    "        return samples\n",
    "    \n",
    "    def extract_samples(\n",
    "        self,\n",
    "        seq_of_obs: torch.tensor,\n",
    "        prediction_length_k: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        each obs is allready a framesack, so we can just go util length - k\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for i in range(seq_of_obs.shape[0] - prediction_length_k):\n",
    "            anchor = seq_of_obs[i]\n",
    "            positive = seq_of_obs[i + prediction_length_k]\n",
    "            samples.append(torch.stack((anchor, positive), dim=0))\n",
    "        return samples\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "samples = []\n",
    "n_episodes = 1\n",
    "for _ in range(n_episodes):\n",
    "    obs = env.reset()\n",
    "    # first to array to preserver fram stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast(anchor, positives):\n",
    "        anchor = forward_mlp(anchor)\n",
    "        pred = (anchor)\n",
    "        logits = torch.matmul(pred, positives.T)\n",
    "        # TODO we could normalize here\n",
    "        # logits = logits - torch.max(logits, dim=1, keepdim=True)[0]  # normalize\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25426/3536605038.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mpositives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mc_anchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mc_positives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "bs  = 512\n",
    "grad_steps = 100000\n",
    "info_freq  = 1000\n",
    "tau = 0.9\n",
    "device = \"cpu\"\n",
    "latent_size = 8\n",
    "encoder = \n",
    "target_encoder = \n",
    "forward_mlp = create_net(input_size=8, output_size=8).to(device)\n",
    "W = torch.nn.Linear(latent_size, latent_size, bias=False).to(device)\n",
    "forward_mlp\n",
    "indices = np.arange(len(dataset))\n",
    "choices = np.random.choice(indices, size=bs)\n",
    "batch_elements = [dataset[choice] for choice in choices]\n",
    "batch = torch.stack(batch_elements).to(device)\n",
    "anchors = batch[:, 0]\n",
    "positives = batch[:, 1]\n",
    "c_anchors = encoder(anchors)\n",
    "with torch.no_grad():\n",
    "        c_positives = target_encoder(positives)\n",
    "batch.shape, anchors.shape\n",
    "logits = contrast(anchor=c_anchors, positives=c_positives)\n",
    "labels = torch.arange(c_anchors.shape[0], dtype=torch.long, device=device)\n",
    "# batch[0], anchors[0], positives[0]\n",
    "ce_loss = torch.nn.CrossEntropyLoss()\n",
    "loss = ce_loss(logits, labels)\n",
    "c_anchors.shape , c_positives.shape, logits.shape,labels.shape, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25426/3676111032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epiosde {} loss {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
